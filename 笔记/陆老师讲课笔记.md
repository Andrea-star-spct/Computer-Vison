semantic gap

对抗样本：人看来不同，但计算机会相同

尺度：空间尺度表征，把一个图片通过一个函数变成不同尺度的图片，现在就是堆数据，总有一个数据是用到的

视角差异

类内差异：谁家的狗 intraclass variation     人脸识别，和基本的图像识别不同，损失函数用contrustive training，特征工程一样的

照明  illumination    background cluster背景混淆   occlusion遮挡  deformation变形

早期的分类方法（可扩展性差）-》数据驱动

##### 香草分类器：

使用最近的距离，最近的那个作为标签

图片距离：L1距离

训练集里有多少个图片，就要计算多少次距离，预测快，训练慢可以的

outlier会有分类错误

##### KNN：

空白区域：要么完全随机。。

L2边缘比L1更平滑

超参数：选取的邻居个数:k  选取的距离计算方式

做回归的时候，正则项，不然会过拟合

##### 最优超参数：

训练集和测试集，防止过拟合，不知道在其他测试集上的泛化能力

验证集，分成3份 6:2：2。。。

交叉验证，训练代价非常高，对于深度学习较少使用 也不一定 是否有必要要探讨

训练一折本来就要一天，一个月

甚至验证集都扔掉，但建议第3种

取accuracy 稳定的K



没有weight non-parameter

直接比较像素点的距离，其实不然，颜色相近即可

对训练集的要求较高，维度灾难



##### 线性分类器：

数值大的比如后视镜。。

W决定了角度，b决定了偏移  W代表了一个超平面

非线性空间处理：在线性分类器中加一些非线性项，复杂度很高；SVM，改变kernel function



sigmoid->tanh 因为0-1之间会有问题->(-1,1)
ReLU>sigmoid 

激活函数也是超参，要去尝试



非线性：AND  OR

64->32精度 区别不大

在求梯度的时候查0.1不碍事





把卷积神经网络放到GPU去上，

AlexNet 在实际的图形识别的效果上面，得到了很大的提升。

为什么分成两块，因为受限于当时的算力，在2块GPU上

通常好一点的GPU 20-30G 











